{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Models, Losses, and Metrics with CREsted\n",
    "\n",
    "This tutorial demonstrates CREsted's flexibility in working with custom model architectures, loss functions, and metrics across different deep learning backends (TensorFlow and PyTorch) via Keras 3.\n",
    "\n",
    "CREsted is built on Keras 3, which means you can seamlessly switch between TensorFlow and PyTorch backends while using the same high-level API. This tutorial shows how to:\n",
    "\n",
    "1. Create custom model architectures for both backends\n",
    "2. Implement custom loss functions and metrics\n",
    "3. Use custom training loops (PyTorch example)\n",
    "\n",
    "The key advantage is that your custom components work identically regardless of the backend, giving you the flexibility to choose the best framework for your specific use case. You could, for example, quickly test a novel loss function that you found in some paper's codebase, whether it's implemented in torch, tf, or keras code, all within the CREsted framework.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Backend Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-21 15:53:49.254\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mcrested.tl\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m34\u001b[0m - \u001b[33m\u001b[1mmodiscolite is not installed, 'crested.tl.modisco' module will not be available.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras backend: torch\n",
      "Keras version: 3.11.2\n",
      "PyTorch version: 2.8.0+cu128\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import crested  # import crested before keras to ensure correct backend setup\n",
    "import keras\n",
    "\n",
    "# Check which backend we're using\n",
    "print(f\"Keras backend: {keras.backend.backend()}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    "\n",
    "# Import backend-specific modules if needed\n",
    "if keras.backend.backend() == \"tensorflow\":\n",
    "    import tensorflow as tf\n",
    "\n",
    "    print(f\"TensorFlow version: {tf.__version__}\")\n",
    "elif keras.backend.backend() == \"torch\":\n",
    "    import torch\n",
    "\n",
    "    print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "We'll use the same mouse cortex dataset from the main tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-21T16:09:49.058203+0200 INFO Genome mm10 registered.\n",
      "Dataset shape: (19, 91477)\n",
      "Cell types: ['Astro', 'Endo', 'L2_3IT', 'L5ET', 'L5IT', 'L5_6NP', 'L6CT', 'L6IT', 'L6b', 'Lamp5', 'Micro_PVM', 'OPC', 'Oligo', 'Pvalb', 'Sncg', 'Sst', 'SstChodl', 'VLMC', 'Vip']\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data (assuming you've run the main tutorial)\n",
    "import anndata as ad\n",
    "\n",
    "adata = ad.read_h5ad(\"data/mouse_cortex_filtered.h5ad\")\n",
    "\n",
    "# Register genome\n",
    "genome = crested.Genome(fasta=\"data/genomes/mm10/mm10.fa\", chrom_sizes=\"data/genomes/mm10/mm10.chrom.sizes\")\n",
    "crested.register_genome(genome)\n",
    "\n",
    "print(f\"Dataset shape: {adata.shape}\")\n",
    "print(f\"Cell types: {list(adata.obs_names)}\")\n",
    "\n",
    "# Setup datamodule\n",
    "datamodule = crested.tl.data.AnnDataModule(\n",
    "    adata,\n",
    "    batch_size=64,\n",
    "    max_stochastic_shift=3,\n",
    "    always_reverse_complement=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model Architectures\n",
    "\n",
    "CREsted works with any Keras model, regardless of how it's implemented under the hood. Here we show the same simple CNN architecture implemented in different ways depending on your backend preference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Keras Model (Framework Agnostic)\n",
    "\n",
    "This approach works identically with both TensorFlow and PyTorch backends.  \n",
    "If you write your model in keras code (recent tf versions also follow this syntax), then keras will use the detected framework as backend for running the computations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created with 309,651 parameters\n"
     ]
    }
   ],
   "source": [
    "def create_simple_cnn_keras(seq_len=2114, num_classes=19):\n",
    "    \"\"\"Simple CNN model using standard Keras layers.\"\"\"\n",
    "    inputs = keras.layers.Input(shape=(seq_len, 4))\n",
    "\n",
    "    # First conv block\n",
    "    x = keras.layers.Conv1D(128, 15, activation=\"relu\", padding=\"same\")(inputs)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.MaxPooling1D(8)(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    # Second conv block\n",
    "    x = keras.layers.Conv1D(256, 7, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.MaxPooling1D(4)(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    # Global pooling and dense layers\n",
    "    x = keras.layers.GlobalAveragePooling1D()(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dropout(0.3)(x)\n",
    "    outputs = keras.layers.Dense(num_classes, activation=\"softplus\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"simple_cnn_keras\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create the model\n",
    "keras_model = create_simple_cnn_keras(seq_len=2114, num_classes=len(adata.obs_names))\n",
    "print(f\"Model created with {keras_model.count_params():,} parameters\")\n",
    "\n",
    "# you would now use this model architecture as input to the crested.tl.Crested trainer class as before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom torch models\n",
    "\n",
    "If you prefer to write your custom models in pytorch, then that works too!  \n",
    "You just have to make sure you have a CREsted environment with torch installed instead of tensorflow.  \n",
    "There are two options if you prefer to write your models in torch directly:\n",
    "1) Write your model in pure torch without any changes. This means you won't be able to use the `tl.Crested` training class though, since keras and torch compile models differently, so you'll have to write a custom training loop that uses CREsted's dataloaders (see bottom of tutorial). This is only the case for model definitions; losses and metrics you can still write in pure torch and use within CREsted as usual.  \n",
    "2) The second option is easier: write your torch model inside a class that inherits from `keras.Model` and make sure to wrap any torch layers that uses parameters with a `keras.layers.TorchModuleWrapper`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure PyTorch model created with 308,883 parameters\n",
      "Keras+PyTorch hybrid model created with 308,883 parameters\n"
     ]
    }
   ],
   "source": [
    "if keras.backend.backend() == \"torch\":\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    from keras.layers import TorchModuleWrapper\n",
    "\n",
    "    # Method 1: Pure PyTorch model (for custom training loops)\n",
    "    class PurePyTorchModel(nn.Module):\n",
    "        \"\"\"Pure PyTorch model equivalent to the Keras CNN.\"\"\"\n",
    "\n",
    "        def __init__(self, num_classes):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv1d(4, 128, 15, padding=7)\n",
    "            self.bn1 = nn.BatchNorm1d(128)\n",
    "            self.pool1 = nn.MaxPool1d(8)\n",
    "            self.dropout1 = nn.Dropout(0.2)\n",
    "\n",
    "            self.conv2 = nn.Conv1d(128, 256, 7, padding=3)\n",
    "            self.bn2 = nn.BatchNorm1d(256)\n",
    "            self.pool2 = nn.MaxPool1d(4)\n",
    "            self.dropout2 = nn.Dropout(0.2)\n",
    "\n",
    "            self.fc1 = nn.Linear(256, 256)\n",
    "            self.dropout3 = nn.Dropout(0.3)\n",
    "            self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "        def forward(self, x):\n",
    "            \"\"\"Forward pass for the PyTorch model.\"\"\"\n",
    "            # Input: (batch, seq_len, 4) -> (batch, 4, seq_len) for Conv1d\n",
    "            x = x.transpose(1, 2)\n",
    "\n",
    "            # First conv block (matching Keras model exactly)\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x = self.bn1(x)\n",
    "            x = self.pool1(x)\n",
    "            x = self.dropout1(x)\n",
    "\n",
    "            # Second conv block\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = self.bn2(x)\n",
    "            x = self.pool2(x)\n",
    "            x = self.dropout2(x)\n",
    "\n",
    "            # Global average pooling\n",
    "            x = F.adaptive_avg_pool1d(x, 1).squeeze(-1)\n",
    "\n",
    "            # Dense layers\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.dropout3(x)\n",
    "            x = F.softplus(self.fc2(x))\n",
    "            return x\n",
    "\n",
    "    # Method 2: Keras model using PyTorch operations\n",
    "    class KerasModelWithPyTorch(keras.Model):\n",
    "        \"\"\"Keras model that uses PyTorch operations wrapped in TorchModuleWrapper.\"\"\"\n",
    "\n",
    "        def __init__(self, seq_len, num_classes, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            self.seq_len = seq_len\n",
    "\n",
    "            # Wrap PyTorch modules with TorchModuleWrapper when they contain parameters\n",
    "            self.conv1 = TorchModuleWrapper(nn.Conv1d(4, 128, 15, padding=7))\n",
    "            self.bn1 = TorchModuleWrapper(nn.BatchNorm1d(128))\n",
    "            self.pool1 = nn.MaxPool1d(8)  # No parameters, no need to wrap\n",
    "            self.dropout1 = nn.Dropout(0.2)\n",
    "\n",
    "            self.conv2 = TorchModuleWrapper(nn.Conv1d(128, 256, 7, padding=3))\n",
    "            self.bn2 = TorchModuleWrapper(nn.BatchNorm1d(256))\n",
    "            self.pool2 = nn.MaxPool1d(4)\n",
    "            self.dropout2 = nn.Dropout(0.2)\n",
    "\n",
    "            self.fc1 = TorchModuleWrapper(nn.Linear(256, 256))\n",
    "            self.dropout3 = nn.Dropout(0.3)\n",
    "            self.fc2 = TorchModuleWrapper(nn.Linear(256, num_classes))\n",
    "\n",
    "        def call(self, inputs):\n",
    "            \"\"\"Forward pass for the Keras model using PyTorch operations.\"\"\"\n",
    "            # Transpose for PyTorch Conv1d: (batch, seq_len, 4) -> (batch, 4, seq_len)\n",
    "            x = inputs.transpose(1, 2)\n",
    "\n",
    "            # First conv block using PyTorch operations\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x = self.bn1(x)\n",
    "            x = self.pool1(x)\n",
    "            x = self.dropout1(x)\n",
    "\n",
    "            # Second conv block\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = self.bn2(x)\n",
    "            x = self.pool2(x)\n",
    "            x = self.dropout2(x)\n",
    "\n",
    "            # Global average pooling\n",
    "            x = F.adaptive_avg_pool1d(x, 1).squeeze(-1)\n",
    "\n",
    "            # Dense layers\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.dropout3(x)\n",
    "            x = F.softplus(self.fc2(x))\n",
    "            return x\n",
    "\n",
    "    # Create both models\n",
    "    num_classes = len(adata.obs_names)\n",
    "    seq_len = 2114\n",
    "\n",
    "    # Pure PyTorch model (for custom training loops)\n",
    "    pure_pytorch_model = PurePyTorchModel(num_classes)\n",
    "    pytorch_params = sum(p.numel() for p in pure_pytorch_model.parameters())\n",
    "    print(f\"Pure PyTorch model created with {pytorch_params:,} parameters\")\n",
    "\n",
    "    # Keras model with PyTorch components (for CREsted workflow)\n",
    "    keras_pytorch_model = KerasModelWithPyTorch(seq_len, num_classes)\n",
    "    # Build the model to count parameters\n",
    "    keras_pytorch_model.build((None, seq_len, 4))\n",
    "    print(f\"Keras+PyTorch hybrid model created with {keras_pytorch_model.count_params():,} parameters\")\n",
    "\n",
    "    # Use the hybrid model for CREsted training (it works with CREsted.fit())\n",
    "    model = keras_pytorch_model\n",
    "\n",
    "else:\n",
    "    print(\"PyTorch-specific examples only available with PyTorch backend\")\n",
    "    model = keras_model  # Use the standard Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss Functions\n",
    "\n",
    "CREsted can work with any Keras or Torch-compatible loss function. Here we show how to implement custom losses that work across different backends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating losses for torch backend.\n",
      "<__main__.create_custom_loss_backend_specific.<locals>.PyTorchCustomLoss object at 0x72a3be54c590>\n"
     ]
    }
   ],
   "source": [
    "# Framework-agnostic custom loss using Keras ops\n",
    "class WeightedMSELoss(keras.losses.Loss):\n",
    "    \"\"\"Custom weighted MSE loss that works with any backend.\"\"\"\n",
    "\n",
    "    def __init__(self, class_weights=None, name=\"weighted_mse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        \"\"\"Compute weighted mean squared error loss.\"\"\"\n",
    "        # Use keras.ops for backend-agnostic operations\n",
    "        mse = keras.ops.square(y_true - y_pred)\n",
    "\n",
    "        if self.class_weights is not None:\n",
    "            # Apply class-specific weights\n",
    "            weights = keras.ops.convert_to_tensor(self.class_weights)\n",
    "            mse = mse * weights\n",
    "\n",
    "        return keras.ops.mean(mse)\n",
    "\n",
    "\n",
    "# Backend-specific loss implementations\n",
    "def create_custom_loss_backend_specific():\n",
    "    \"\"\"Create custom loss using backend-specific operations.\"\"\"\n",
    "    if keras.backend.backend() == \"tensorflow\":\n",
    "        import tensorflow as tf\n",
    "\n",
    "        class TensorFlowCustomLoss(keras.losses.Loss):\n",
    "            def __init__(self, alpha=1.0, name=\"tf_custom_loss\", **kwargs):\n",
    "                super().__init__(name=name, **kwargs)\n",
    "                self.alpha = alpha\n",
    "\n",
    "            def call(self, y_true, y_pred):\n",
    "                # Use TensorFlow operations directly\n",
    "                mse = tf.square(y_true - y_pred)\n",
    "                # Add custom TF-specific regularization\n",
    "                l2_reg = tf.reduce_sum(tf.square(y_pred)) * 0.001\n",
    "                return tf.reduce_mean(mse) + self.alpha * l2_reg\n",
    "\n",
    "        return TensorFlowCustomLoss()\n",
    "\n",
    "    elif keras.backend.backend() == \"torch\":\n",
    "        import torch\n",
    "\n",
    "        class PyTorchCustomLoss(keras.losses.Loss):\n",
    "            def __init__(self, alpha=1.0, name=\"torch_custom_loss\", **kwargs):\n",
    "                super().__init__(name=name, **kwargs)\n",
    "                self.alpha = alpha\n",
    "\n",
    "            def call(self, y_true, y_pred):\n",
    "                # Use PyTorch operations directly\n",
    "                mse = torch.square(y_true - y_pred)\n",
    "                l2_reg = torch.sum(torch.square(y_pred)) * 0.001\n",
    "                return torch.mean(mse) + self.alpha * l2_reg\n",
    "\n",
    "        return PyTorchCustomLoss()\n",
    "\n",
    "\n",
    "# Create loss functions\n",
    "print(f\"Creating losses for {keras.backend.backend()} backend.\")\n",
    "\n",
    "# Framework-agnostic loss\n",
    "class_weights = np.ones(len(adata.obs_names))  # Equal weights for demo\n",
    "weighted_loss = WeightedMSELoss(class_weights=class_weights)\n",
    "\n",
    "# Backend-specific loss\n",
    "backend_loss = create_custom_loss_backend_specific()\n",
    "print(backend_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Metrics\n",
    "\n",
    "Similar to losses, you can create custom metrics that work across backends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating metrics for torch backend:\n",
      "[<MeanAbsoluteError name=mean_absolute_error>, <CosineSimilarity name=cosine_similarity>, <SpearmanCorrelation name=spearman_corr>, <PyTorchR2Score name=torch_r2_score>]\n"
     ]
    }
   ],
   "source": [
    "# Framework-agnostic custom metric\n",
    "class SpearmanCorrelation(keras.metrics.Metric):\n",
    "    \"\"\"Custom Spearman correlation metric that works with any backend.\"\"\"\n",
    "\n",
    "    def __init__(self, name=\"spearman_corr\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.correlation_sum = self.add_weight(name=\"correlation_sum\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(name=\"count\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \"\"\"Update state with new predictions and true values.\"\"\"\n",
    "        # Simplified Spearman correlation (rank correlation)\n",
    "        # For demo - real implementation would be more complex\n",
    "        pearson = keras.ops.sum(\n",
    "            (y_true - keras.ops.mean(y_true, axis=0)) * (y_pred - keras.ops.mean(y_pred, axis=0)),\n",
    "            axis=0,\n",
    "        )\n",
    "        norm_factor = keras.ops.sqrt(\n",
    "            keras.ops.sum(keras.ops.square(y_true - keras.ops.mean(y_true, axis=0)), axis=0)\n",
    "            * keras.ops.sum(keras.ops.square(y_pred - keras.ops.mean(y_pred, axis=0)), axis=0)\n",
    "        )\n",
    "        correlation = keras.ops.mean(pearson / (norm_factor + 1e-8))\n",
    "\n",
    "        self.correlation_sum.assign_add(correlation)\n",
    "        self.count.assign_add(1.0)\n",
    "\n",
    "    def result(self):\n",
    "        \"\"\"Returns the average correlation.\"\"\"\n",
    "        return self.correlation_sum / self.count\n",
    "\n",
    "    def reset_state(self):\n",
    "        \"\"\"Reset the state of the metric.\"\"\"\n",
    "        self.correlation_sum.assign(0.0)\n",
    "        self.count.assign(0.0)\n",
    "\n",
    "\n",
    "# Or, write backend-specific metrics\n",
    "def create_custom_metric_backend_specific():\n",
    "    \"\"\"Create custom metric using backend-specific operations.\"\"\"\n",
    "    if keras.backend.backend() == \"tensorflow\":\n",
    "        import tensorflow as tf\n",
    "\n",
    "        class TensorFlowR2Score(keras.metrics.Metric):\n",
    "            def __init__(self, name=\"tf_r2_score\", **kwargs):\n",
    "                super().__init__(name=name, **kwargs)\n",
    "                self.total_sum_squares = self.add_weight(name=\"tss\", initializer=\"zeros\")\n",
    "                self.residual_sum_squares = self.add_weight(name=\"rss\", initializer=\"zeros\")\n",
    "\n",
    "            def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "                # Using TensorFlow operations directly\n",
    "                y_mean = tf.reduce_mean(y_true)\n",
    "                tss = tf.reduce_sum(tf.square(y_true - y_mean))\n",
    "                rss = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "\n",
    "                self.total_sum_squares.assign_add(tss)\n",
    "                self.residual_sum_squares.assign_add(rss)\n",
    "\n",
    "            def result(self):\n",
    "                return 1.0 - (self.residual_sum_squares / (self.total_sum_squares + 1e-8))\n",
    "\n",
    "            def reset_state(self):\n",
    "                self.total_sum_squares.assign(0.0)\n",
    "                self.residual_sum_squares.assign(0.0)\n",
    "\n",
    "        return TensorFlowR2Score()\n",
    "\n",
    "    elif keras.backend.backend() == \"torch\":\n",
    "        import torch\n",
    "\n",
    "        class PyTorchR2Score(keras.metrics.Metric):\n",
    "            def __init__(self, name=\"torch_r2_score\", **kwargs):\n",
    "                super().__init__(name=name, **kwargs)\n",
    "                self.total_sum_squares = self.add_weight(name=\"tss\", initializer=\"zeros\")\n",
    "                self.residual_sum_squares = self.add_weight(name=\"rss\", initializer=\"zeros\")\n",
    "\n",
    "            def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "                # Using PyTorch operations directly\n",
    "                y_mean = torch.mean(y_true)\n",
    "                tss = torch.sum(torch.square(y_true - y_mean))\n",
    "                rss = torch.sum(torch.square(y_true - y_pred))\n",
    "\n",
    "                self.total_sum_squares.assign_add(tss)\n",
    "                self.residual_sum_squares.assign_add(rss)\n",
    "\n",
    "            def result(self):\n",
    "                return 1.0 - (self.residual_sum_squares / (self.total_sum_squares + 1e-8))\n",
    "\n",
    "            def reset_state(self):\n",
    "                self.total_sum_squares.assign(0.0)\n",
    "                self.residual_sum_squares.assign(0.0)\n",
    "\n",
    "        return PyTorchR2Score()\n",
    "\n",
    "\n",
    "# Create metrics\n",
    "print(f\"Creating metrics for {keras.backend.backend()} backend:\")\n",
    "\n",
    "# Framework-agnostic metric\n",
    "spearman_metric = SpearmanCorrelation()\n",
    "\n",
    "# Backend-specific metric\n",
    "r2_metric = create_custom_metric_backend_specific()\n",
    "\n",
    "# Standard metrics that work with both backends\n",
    "standard_metrics = [\n",
    "    keras.metrics.MeanAbsoluteError(),\n",
    "    keras.metrics.CosineSimilarity(axis=1),\n",
    "    spearman_metric,\n",
    "    r2_metric,\n",
    "]\n",
    "print(standard_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Training with CREsted\n",
    "\n",
    "You can use CREsted's standard training workflow or implement custom training loops. Here's an example of custom training when using the PyTorch backend with our custom model, metrics, and loss.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom training loop with the `tl.Crested` framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.create_custom_loss_backend_specific.<locals>.PyTorchCustomLoss object at 0x72a3be54c590>\n"
     ]
    }
   ],
   "source": [
    "print(backend_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"keras_model_with_py_torch_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"keras_model_with_py_torch_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ torch_module_wrapper_23         │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,808</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TorchModuleWrapper</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ torch_module_wrapper_24         │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TorchModuleWrapper</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ torch_module_wrapper_25         │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TorchModuleWrapper</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ torch_module_wrapper_26         │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TorchModuleWrapper</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ torch_module_wrapper_27         │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">229,632</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TorchModuleWrapper</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ torch_module_wrapper_28         │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TorchModuleWrapper</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ torch_module_wrapper_29         │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TorchModuleWrapper</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ torch_module_wrapper_30         │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TorchModuleWrapper</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ torch_module_wrapper_31         │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TorchModuleWrapper</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ torch_module_wrapper_32         │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TorchModuleWrapper</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ torch_module_wrapper_33         │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,883</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TorchModuleWrapper</span>)            │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ torch_module_wrapper_23         │ ?                      │         \u001b[38;5;34m7,808\u001b[0m │\n",
       "│ (\u001b[38;5;33mTorchModuleWrapper\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ torch_module_wrapper_24         │ ?                      │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mTorchModuleWrapper\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ torch_module_wrapper_25         │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTorchModuleWrapper\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ torch_module_wrapper_26         │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTorchModuleWrapper\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ torch_module_wrapper_27         │ ?                      │       \u001b[38;5;34m229,632\u001b[0m │\n",
       "│ (\u001b[38;5;33mTorchModuleWrapper\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ torch_module_wrapper_28         │ ?                      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mTorchModuleWrapper\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ torch_module_wrapper_29         │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTorchModuleWrapper\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ torch_module_wrapper_30         │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTorchModuleWrapper\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ torch_module_wrapper_31         │ ?                      │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "│ (\u001b[38;5;33mTorchModuleWrapper\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ torch_module_wrapper_32         │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTorchModuleWrapper\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ torch_module_wrapper_33         │ ?                      │         \u001b[38;5;34m4,883\u001b[0m │\n",
       "│ (\u001b[38;5;33mTorchModuleWrapper\u001b[0m)            │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">308,883</span> (1.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m308,883\u001b[0m (1.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">308,883</span> (1.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m308,883\u001b[0m (1.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "2025-08-21T16:10:17.146763+0200 INFO Loading sequences into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73325/73325 [00:06<00:00, 11300.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-21T16:10:24.141689+0200 INFO Loading sequences into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9952/9952 [00:01<00:00, 9915.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m2292/2292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 42ms/step - cosine_similarity: 0.6523 - loss: 28.2246 - mean_absolute_error: 2.8233 - spearman_corr: 0.1557 - torch_r2_score: 0.0570 - val_cosine_similarity: 0.6516 - val_loss: 28.7826 - val_mean_absolute_error: 2.3636 - val_spearman_corr: 0.1725 - val_torch_r2_score: -5.8913e-04 - learning_rate: 0.0010\n",
      "Epoch 2/2\n",
      "\u001b[1m2292/2292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 43ms/step - cosine_similarity: 0.6580 - loss: 27.5134 - mean_absolute_error: 2.7868 - spearman_corr: 0.1910 - torch_r2_score: 0.0807 - val_cosine_similarity: 0.6574 - val_loss: 28.2391 - val_mean_absolute_error: 2.3365 - val_spearman_corr: 0.2021 - val_torch_r2_score: 0.0183 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Create TaskConfig with custom components\n",
    "custom_config = crested.tl.TaskConfig(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=backend_loss,  # Our custom loss (pure torch in my case)\n",
    "    metrics=standard_metrics,  # Our custom metrics\n",
    ")\n",
    "\n",
    "# Train using CREsted framework\n",
    "trainer = crested.tl.Crested(\n",
    "    data=datamodule,\n",
    "    model=model,  # with a torch environment this uses our \"keras-torch hybrid\" model\n",
    "    config=custom_config,\n",
    "    project_name=\"custom_tutorial\",\n",
    "    run_name=\"framework_agnostic\",\n",
    ")\n",
    "\n",
    "# Quick training for demo (just 2 epochs)\n",
    "trainer.fit(epochs=2, learning_rate_reduce_patience=1, early_stopping_patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete custom training loop example (PyTorch backend only)\n",
    "\n",
    "If you want a complete custom training loop but still want to make use of the `Crested` dataloaders, then that's possible too.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 2114, 4]) torch.Size([64, 19])\n"
     ]
    }
   ],
   "source": [
    "# datamodule contains pytorch DataLoader when using torch backend\n",
    "for x, y in datamodule.train_dataloader.data:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 - Custom Loss: 21.7358\n",
      "Epoch 2/2 - Custom Loss: 21.3225\n",
      "Custom PyTorch training completed\n"
     ]
    }
   ],
   "source": [
    "# Custom training loop example (PyTorch backend)\n",
    "if keras.backend.backend() == \"torch\":\n",
    "    import torch\n",
    "\n",
    "    custom_model = pure_pytorch_model  # Use the pure PyTorch model\n",
    "    custom_model.to(device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    optimizer = torch.optim.Adam(custom_model.parameters(), lr=1e-3)\n",
    "    custom_model.train()\n",
    "\n",
    "    # Get training data from Crested datamodule\n",
    "    train_loader = datamodule.train_dataloader.data\n",
    "\n",
    "    # Custom training loop\n",
    "    for epoch in range(2):  # Just 2 epochs for demo\n",
    "        epoch_loss = 0.0\n",
    "        num_batches = 0\n",
    "\n",
    "        for batch_idx, (sequences, targets) in enumerate(train_loader):\n",
    "            if batch_idx >= 10:  # Limit batches for demo\n",
    "                break\n",
    "\n",
    "            with torch.enable_grad():\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                predictions = custom_model(sequences)\n",
    "\n",
    "                # Calculate loss\n",
    "                loss_value = backend_loss(targets, predictions)\n",
    "\n",
    "                # Backward pass - get gradients\n",
    "                loss_value.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss_value.item()\n",
    "                num_batches += 1\n",
    "\n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        print(f\"Epoch {epoch + 1}/2 - Custom Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    print(\"Custom PyTorch training completed\")\n",
    "\n",
    "else:\n",
    "    print(\"Custom training loop example only available with PyTorch backend\")\n",
    "    print(\"Current backend:\", keras.backend.backend())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crested_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
