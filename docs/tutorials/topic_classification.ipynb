{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Topic classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We can use the outputs of [pycisTopic](https://pycistopic.readthedocs.io/en/latest/) to train a model to predict topic probabilities for a given sequence.  \n",
    "\n",
    "Since we plan on adding detailed use cases describing topic classification later on, we will only provide a brief overview of the workflow here. Refer to the [introductory notebook](model_training_and_eval) for a more detailed explanation of the CREsted workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Set package settings\n",
    "import matplotlib\n",
    "import os\n",
    "\n",
    "## Set the font type to ensure text is saved as whole words\n",
    "matplotlib.rcParams[\"pdf.fonttype\"] = 42  # Use TrueType fonts instead of Type 3 fonts\n",
    "matplotlib.rcParams[\"ps.fonttype\"] = 42  # For PostScript as well, if needed\n",
    "\n",
    "## Set the base directory for data retrieval with crested.get_dataset()/get_model()\n",
    "os.environ['CRESTED_DATA_DIR'] = '/staging/leuven/stg_00002/lcb/cblaauw/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data\n",
    "\n",
    "For this tutorial, we will use the mouse BICCN dataset. We will use the preprocessed, binarized outputs of pycisTopic as input data for the topic classification model. \n",
    "\n",
    "To train a topic classification model, we need the following data:\n",
    "1. A folder containing BED files per topic (output of pycisTopic). \n",
    "2. A genome fasta and optionally a chromosome sizes file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-16T15:04:11.542386+0100 INFO Genome genome registered.\n"
     ]
    }
   ],
   "source": [
    "# Set the genome\n",
    "genome = crested.Genome(\"mm10/genome.fa\", \"mm10/genome.chrom.sizes\")\n",
    "crested.register_genome(genome)  # Register the genome so that it's automatically used in every function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'data/mouse_biccn/beds.tar.gz' from 'https://resources.aertslab.org/CREsted/data/mouse_biccn/beds.tar.gz' to '/staging/leuven/stg_00002/lcb/cblaauw'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff75eba7808d4a859babee48cf8d1340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                              | 0.00/12.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Untarring contents of '/staging/leuven/stg_00002/lcb/cblaauw/data/mouse_biccn/beds.tar.gz' to '/staging/leuven/stg_00002/lcb/cblaauw/data/mouse_biccn/beds.tar.gz.untar'\n"
     ]
    }
   ],
   "source": [
    "# Download the tutorial data\n",
    "beds_folder, regions_file = crested.get_dataset(\"mouse_cortex_bed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can import a folder of BED files using the {func}`crested.import_beds` function.  \n",
    "This will return an Anndata object with the regions as .var and the bed file names  as .obs (here: our Topics).  \n",
    "In this case, the adata.X values are binary, representing whether that region is associated with a topic or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-16T15:03:14.757905+0100 WARNING Chromsizes file not provided. Will not check if regions are within chromosomes\n",
      "2026-02-16T15:03:15.642825+0100 INFO Reading bed files from /staging/leuven/stg_00002/lcb/cblaauw/data/mouse_biccn/beds.tar.gz.untar and using /staging/leuven/stg_00002/lcb/cblaauw/data/mouse_biccn/consensus_peaks_biccn.bed as var_names...\n",
      "2026-02-16T15:03:29.218412+0100 WARNING 107610 consensus regions are not open in any class. Removing them from the AnnData object. Disable this behavior by setting 'remove_empty_regions=False'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 80 × 439383\n",
       "    obs: 'file_path', 'n_open_regions'\n",
       "    var: 'n_classes', 'chr', 'start', 'end'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the beds into an AnnData object - the regions file is optional for import_beds\n",
    "adata = crested.import_beds(beds_folder=beds_folder, regions_file=regions_file)\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 80 classes (topics) and 439386 regions in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "For topic classification there is little preprocessing to be performed compared to peak regression.  \n",
    "The data does not need to be normalized since the values are binary and we don't filter any regions on specificity since by nature of topic modelling the selected regions should already be 'meaningful' regions.  \n",
    "You could change the width of the regions, but we tend to keep the regions at 500bp for topic classification.  \n",
    "\n",
    "The only preprocessing step we need to perform is to split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-16T15:03:29.634609+0100 INFO Lazily importing module crested.pp. This could take a second...\n",
      "split\n",
      "train    354013\n",
      "val       45113\n",
      "test      40257\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Standard train/val/test split\n",
    "crested.pp.train_val_test_split(adata, strategy=\"chr\", val_chroms=[\"chr8\", \"chr10\"], test_chroms=[\"chr9\", \"chr18\"])\n",
    "print(adata.var[\"split\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Model training has the same workflow as peak regression. The only differences are:\n",
    "1. We select a different model architecture. Since we're training on 500bp regions we don't need the dilated convolutions of the dilated CNN.  \n",
    "2. We select a different config, since we're monitoring other metrics and are using a different loss for classification.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-16T15:04:21.343827+0100 INFO Lazily importing module crested.tl. This could take a second...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1771250736.314264 2306437 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78751 MB memory:  -> device: 0, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:26:00.0, compute capability: 9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaskConfig(optimizer=<keras.src.optimizers.adam.Adam object at 0x14ba081b86e0>, loss=<LossFunctionWrapper(<function binary_crossentropy at 0x14ba02aa5080>, kwargs={'from_logits': False, 'label_smoothing': 0.0, 'axis': -1})>, metrics=[<AUC name=auROC>, <AUC name=auPR>, <CategoricalAccuracy name=categorical_accuracy>])\n"
     ]
    }
   ],
   "source": [
    "# Datamodule\n",
    "datamodule = crested.tl.data.AnnDataModule(\n",
    "    adata,\n",
    "    batch_size=128,  # lower this if you encounter OOM errors\n",
    "    max_stochastic_shift=3,  # optional augmentation\n",
    "    always_reverse_complement=True,  # default True. Will double the effective size of the training dataset.\n",
    ")\n",
    "\n",
    "# Architecture: we will use the DeepTopic CNN model\n",
    "model_architecture = crested.tl.zoo.deeptopic_cnn(seq_len=500, num_classes=80)\n",
    "\n",
    "# Config: we will use the default topic classification config (binary cross entropy loss and AUC/ROC metrics)\n",
    "config = crested.tl.default_configs(\"topic_classification\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the trainer object and train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = crested.tl.Crested(\n",
    "    data=datamodule,\n",
    "    model=model_architecture,\n",
    "    config=config,\n",
    "    project_name=\"mouse_biccn\",  # change to your liking\n",
    "    run_name=\"topic_classification\",\n",
    "    logger='wandb',  # or 'tensorboard', None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ sequence            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">69,632</span> │ sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,767,168</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,883,584</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,310,720</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ denseblock_dense    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,576</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ denseblock_batchno… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ denseblock_dense… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ denseblock_activat… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ denseblock_batch… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ denseblock_dropout  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ denseblock_activ… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">82,000</span> │ denseblock_dropo… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ sequence            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m4\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1024\u001b[0m) │     \u001b[38;5;34m69,632\u001b[0m │ sequence[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1024\u001b[0m) │      \u001b[38;5;34m4,096\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1024\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m1024\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m1024\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │  \u001b[38;5;34m5,767,168\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │      \u001b[38;5;34m2,048\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,883,584\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m2,048\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_2[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │  \u001b[38;5;34m1,310,720\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,048\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_3[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │    \u001b[38;5;34m524,288\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,048\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ denseblock_dense    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │  \u001b[38;5;34m1,048,576\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ denseblock_batchno… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │      \u001b[38;5;34m4,096\u001b[0m │ denseblock_dense… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ denseblock_activat… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ denseblock_batch… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ denseblock_dropout  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ denseblock_activ… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m82,000\u001b[0m │ denseblock_dropo… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,702,352</span> (44.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,702,352\u001b[0m (44.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,694,160</span> (44.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,694,160\u001b[0m (44.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> (32.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,192\u001b[0m (32.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "2026-02-16T15:05:49.654130+0100 INFO Loading sequences into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 354013/354013 [00:05<00:00, 62612.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-16T15:05:55.914284+0100 INFO Loading sequences into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45113/45113 [00:00<00:00, 75312.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m  10/5532\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09\u001b[0m 13ms/step - auPR: 0.0467 - auROC: 0.5093 - categorical_accuracy: 0.0112 - loss: 0.7205 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1771250792.706058 2306866 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 17ms/step - auPR: 0.0931 - auROC: 0.6814 - categorical_accuracy: 0.0411 - loss: 0.1609 - val_auPR: 0.1200 - val_auROC: 0.7129 - val_categorical_accuracy: 0.0336 - val_loss: 0.1599 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 14ms/step - auPR: 0.1176 - auROC: 0.7174 - categorical_accuracy: 0.0476 - loss: 0.1559 - val_auPR: 0.1425 - val_auROC: 0.7447 - val_categorical_accuracy: 0.0503 - val_loss: 0.1573 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 13ms/step - auPR: 0.1341 - auROC: 0.7440 - categorical_accuracy: 0.0584 - loss: 0.1552 - val_auPR: 0.1548 - val_auROC: 0.7579 - val_categorical_accuracy: 0.0579 - val_loss: 0.1573 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 14ms/step - auPR: 0.1429 - auROC: 0.7535 - categorical_accuracy: 0.0663 - loss: 0.1546 - val_auPR: 0.1701 - val_auROC: 0.7731 - val_categorical_accuracy: 0.0704 - val_loss: 0.1558 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 14ms/step - auPR: 0.1492 - auROC: 0.7589 - categorical_accuracy: 0.0708 - loss: 0.1537 - val_auPR: 0.1733 - val_auROC: 0.7771 - val_categorical_accuracy: 0.0598 - val_loss: 0.1536 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 14ms/step - auPR: 0.1526 - auROC: 0.7620 - categorical_accuracy: 0.0734 - loss: 0.1526 - val_auPR: 0.1784 - val_auROC: 0.7787 - val_categorical_accuracy: 0.0780 - val_loss: 0.1520 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 14ms/step - auPR: 0.1552 - auROC: 0.7638 - categorical_accuracy: 0.0757 - loss: 0.1516 - val_auPR: 0.1788 - val_auROC: 0.7786 - val_categorical_accuracy: 0.0808 - val_loss: 0.1526 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 15ms/step - auPR: 0.1565 - auROC: 0.7650 - categorical_accuracy: 0.0763 - loss: 0.1510 - val_auPR: 0.1840 - val_auROC: 0.7833 - val_categorical_accuracy: 0.0874 - val_loss: 0.1500 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 15ms/step - auPR: 0.1572 - auROC: 0.7659 - categorical_accuracy: 0.0773 - loss: 0.1505 - val_auPR: 0.1795 - val_auROC: 0.7831 - val_categorical_accuracy: 0.0747 - val_loss: 0.1497 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 14ms/step - auPR: 0.1586 - auROC: 0.7665 - categorical_accuracy: 0.0774 - loss: 0.1501 - val_auPR: 0.1838 - val_auROC: 0.7881 - val_categorical_accuracy: 0.0829 - val_loss: 0.1480 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 14ms/step - auPR: 0.1584 - auROC: 0.7673 - categorical_accuracy: 0.0788 - loss: 0.1498 - val_auPR: 0.1856 - val_auROC: 0.7873 - val_categorical_accuracy: 0.0909 - val_loss: 0.1475 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 14ms/step - auPR: 0.1591 - auROC: 0.7673 - categorical_accuracy: 0.0790 - loss: 0.1496 - val_auPR: 0.1865 - val_auROC: 0.7880 - val_categorical_accuracy: 0.0928 - val_loss: 0.1477 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 15ms/step - auPR: 0.1598 - auROC: 0.7679 - categorical_accuracy: 0.0787 - loss: 0.1494 - val_auPR: 0.1865 - val_auROC: 0.7887 - val_categorical_accuracy: 0.0909 - val_loss: 0.1470 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 14ms/step - auPR: 0.1600 - auROC: 0.7680 - categorical_accuracy: 0.0786 - loss: 0.1493 - val_auPR: 0.1882 - val_auROC: 0.7892 - val_categorical_accuracy: 0.0878 - val_loss: 0.1473 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 14ms/step - auPR: 0.1602 - auROC: 0.7681 - categorical_accuracy: 0.0788 - loss: 0.1492 - val_auPR: 0.1865 - val_auROC: 0.7868 - val_categorical_accuracy: 0.0810 - val_loss: 0.1471 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 14ms/step - auPR: 0.1601 - auROC: 0.7684 - categorical_accuracy: 0.0793 - loss: 0.1490 - val_auPR: 0.1879 - val_auROC: 0.7892 - val_categorical_accuracy: 0.0839 - val_loss: 0.1473 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 14ms/step - auPR: 0.1605 - auROC: 0.7685 - categorical_accuracy: 0.0794 - loss: 0.1490 - val_auPR: 0.1875 - val_auROC: 0.7898 - val_categorical_accuracy: 0.0880 - val_loss: 0.1473 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 14ms/step - auPR: 0.1607 - auROC: 0.7685 - categorical_accuracy: 0.0796 - loss: 0.1489 - val_auPR: 0.1853 - val_auROC: 0.7874 - val_categorical_accuracy: 0.0876 - val_loss: 0.1472 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 14ms/step - auPR: 0.1763 - auROC: 0.7826 - categorical_accuracy: 0.0897 - loss: 0.1437 - val_auPR: 0.2057 - val_auROC: 0.8041 - val_categorical_accuracy: 0.0999 - val_loss: 0.1400 - learning_rate: 2.5000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 15ms/step - auPR: 0.1804 - auROC: 0.7854 - categorical_accuracy: 0.0936 - loss: 0.1421 - val_auPR: 0.2087 - val_auROC: 0.8053 - val_categorical_accuracy: 0.1068 - val_loss: 0.1393 - learning_rate: 2.5000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 14ms/step - auPR: 0.1819 - auROC: 0.7864 - categorical_accuracy: 0.0943 - loss: 0.1417 - val_auPR: 0.2084 - val_auROC: 0.8061 - val_categorical_accuracy: 0.1063 - val_loss: 0.1392 - learning_rate: 2.5000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 15ms/step - auPR: 0.1830 - auROC: 0.7871 - categorical_accuracy: 0.0960 - loss: 0.1415 - val_auPR: 0.2106 - val_auROC: 0.8065 - val_categorical_accuracy: 0.1070 - val_loss: 0.1388 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 13ms/step - auPR: 0.1837 - auROC: 0.7875 - categorical_accuracy: 0.0961 - loss: 0.1415 - val_auPR: 0.2104 - val_auROC: 0.8062 - val_categorical_accuracy: 0.1035 - val_loss: 0.1393 - learning_rate: 2.5000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 14ms/step - auPR: 0.1842 - auROC: 0.7880 - categorical_accuracy: 0.0973 - loss: 0.1414 - val_auPR: 0.2116 - val_auROC: 0.8074 - val_categorical_accuracy: 0.1098 - val_loss: 0.1389 - learning_rate: 2.5000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 14ms/step - auPR: 0.1847 - auROC: 0.7882 - categorical_accuracy: 0.0976 - loss: 0.1414 - val_auPR: 0.2112 - val_auROC: 0.8064 - val_categorical_accuracy: 0.1128 - val_loss: 0.1392 - learning_rate: 2.5000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 13ms/step - auPR: 0.1851 - auROC: 0.7885 - categorical_accuracy: 0.0980 - loss: 0.1414 - val_auPR: 0.2129 - val_auROC: 0.8082 - val_categorical_accuracy: 0.1147 - val_loss: 0.1387 - learning_rate: 2.5000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 14ms/step - auPR: 0.1854 - auROC: 0.7888 - categorical_accuracy: 0.0982 - loss: 0.1413 - val_auPR: 0.2135 - val_auROC: 0.8075 - val_categorical_accuracy: 0.1167 - val_loss: 0.1387 - learning_rate: 2.5000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 14ms/step - auPR: 0.1861 - auROC: 0.7892 - categorical_accuracy: 0.0984 - loss: 0.1413 - val_auPR: 0.2134 - val_auROC: 0.8079 - val_categorical_accuracy: 0.1113 - val_loss: 0.1387 - learning_rate: 2.5000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 14ms/step - auPR: 0.1861 - auROC: 0.7891 - categorical_accuracy: 0.0992 - loss: 0.1413 - val_auPR: 0.2143 - val_auROC: 0.8087 - val_categorical_accuracy: 0.1125 - val_loss: 0.1387 - learning_rate: 2.5000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 14ms/step - auPR: 0.1865 - auROC: 0.7896 - categorical_accuracy: 0.0991 - loss: 0.1412 - val_auPR: 0.2148 - val_auROC: 0.8093 - val_categorical_accuracy: 0.1131 - val_loss: 0.1384 - learning_rate: 2.5000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 14ms/step - auPR: 0.1867 - auROC: 0.7895 - categorical_accuracy: 0.0994 - loss: 0.1413 - val_auPR: 0.2158 - val_auROC: 0.8099 - val_categorical_accuracy: 0.1162 - val_loss: 0.1382 - learning_rate: 2.5000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 14ms/step - auPR: 0.1874 - auROC: 0.7897 - categorical_accuracy: 0.0992 - loss: 0.1412 - val_auPR: 0.2143 - val_auROC: 0.8088 - val_categorical_accuracy: 0.1093 - val_loss: 0.1386 - learning_rate: 2.5000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 13ms/step - auPR: 0.1874 - auROC: 0.7898 - categorical_accuracy: 0.1001 - loss: 0.1412 - val_auPR: 0.2151 - val_auROC: 0.8088 - val_categorical_accuracy: 0.1133 - val_loss: 0.1385 - learning_rate: 2.5000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 14ms/step - auPR: 0.1878 - auROC: 0.7901 - categorical_accuracy: 0.0998 - loss: 0.1412 - val_auPR: 0.2149 - val_auROC: 0.8090 - val_categorical_accuracy: 0.1097 - val_loss: 0.1384 - learning_rate: 2.5000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 14ms/step - auPR: 0.1880 - auROC: 0.7901 - categorical_accuracy: 0.0999 - loss: 0.1412 - val_auPR: 0.2156 - val_auROC: 0.8097 - val_categorical_accuracy: 0.1137 - val_loss: 0.1384 - learning_rate: 2.5000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 16ms/step - auPR: 0.1881 - auROC: 0.7902 - categorical_accuracy: 0.1003 - loss: 0.1411 - val_auPR: 0.2158 - val_auROC: 0.8097 - val_categorical_accuracy: 0.1132 - val_loss: 0.1384 - learning_rate: 2.5000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 14ms/step - auPR: 0.1958 - auROC: 0.7961 - categorical_accuracy: 0.1049 - loss: 0.1396 - val_auPR: 0.2243 - val_auROC: 0.8150 - val_categorical_accuracy: 0.1224 - val_loss: 0.1363 - learning_rate: 6.2500e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 15ms/step - auPR: 0.1987 - auROC: 0.7981 - categorical_accuracy: 0.1072 - loss: 0.1387 - val_auPR: 0.2259 - val_auROC: 0.8158 - val_categorical_accuracy: 0.1228 - val_loss: 0.1358 - learning_rate: 6.2500e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 13ms/step - auPR: 0.1997 - auROC: 0.7990 - categorical_accuracy: 0.1075 - loss: 0.1383 - val_auPR: 0.2264 - val_auROC: 0.8160 - val_categorical_accuracy: 0.1224 - val_loss: 0.1356 - learning_rate: 6.2500e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 13ms/step - auPR: 0.2007 - auROC: 0.7994 - categorical_accuracy: 0.1079 - loss: 0.1380 - val_auPR: 0.2261 - val_auROC: 0.8161 - val_categorical_accuracy: 0.1219 - val_loss: 0.1355 - learning_rate: 6.2500e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 13ms/step - auPR: 0.2012 - auROC: 0.7998 - categorical_accuracy: 0.1079 - loss: 0.1378 - val_auPR: 0.2274 - val_auROC: 0.8163 - val_categorical_accuracy: 0.1213 - val_loss: 0.1353 - learning_rate: 6.2500e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 14ms/step - auPR: 0.2017 - auROC: 0.8000 - categorical_accuracy: 0.1084 - loss: 0.1377 - val_auPR: 0.2273 - val_auROC: 0.8166 - val_categorical_accuracy: 0.1227 - val_loss: 0.1350 - learning_rate: 6.2500e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 14ms/step - auPR: 0.2020 - auROC: 0.8003 - categorical_accuracy: 0.1088 - loss: 0.1376 - val_auPR: 0.2276 - val_auROC: 0.8169 - val_categorical_accuracy: 0.1223 - val_loss: 0.1350 - learning_rate: 6.2500e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 14ms/step - auPR: 0.2021 - auROC: 0.8004 - categorical_accuracy: 0.1081 - loss: 0.1375 - val_auPR: 0.2275 - val_auROC: 0.8163 - val_categorical_accuracy: 0.1236 - val_loss: 0.1351 - learning_rate: 6.2500e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 14ms/step - auPR: 0.2025 - auROC: 0.8007 - categorical_accuracy: 0.1088 - loss: 0.1374 - val_auPR: 0.2274 - val_auROC: 0.8160 - val_categorical_accuracy: 0.1224 - val_loss: 0.1350 - learning_rate: 6.2500e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 14ms/step - auPR: 0.2026 - auROC: 0.8007 - categorical_accuracy: 0.1091 - loss: 0.1374 - val_auPR: 0.2276 - val_auROC: 0.8169 - val_categorical_accuracy: 0.1233 - val_loss: 0.1350 - learning_rate: 6.2500e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 15ms/step - auPR: 0.2025 - auROC: 0.8008 - categorical_accuracy: 0.1091 - loss: 0.1373 - val_auPR: 0.2273 - val_auROC: 0.8166 - val_categorical_accuracy: 0.1208 - val_loss: 0.1350 - learning_rate: 6.2500e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 15ms/step - auPR: 0.2060 - auROC: 0.8031 - categorical_accuracy: 0.1107 - loss: 0.1368 - val_auPR: 0.2302 - val_auROC: 0.8180 - val_categorical_accuracy: 0.1244 - val_loss: 0.1345 - learning_rate: 1.5625e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 14ms/step - auPR: 0.2070 - auROC: 0.8039 - categorical_accuracy: 0.1115 - loss: 0.1366 - val_auPR: 0.2306 - val_auROC: 0.8185 - val_categorical_accuracy: 0.1240 - val_loss: 0.1343 - learning_rate: 1.5625e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 15ms/step - auPR: 0.2073 - auROC: 0.8042 - categorical_accuracy: 0.1118 - loss: 0.1365 - val_auPR: 0.2311 - val_auROC: 0.8188 - val_categorical_accuracy: 0.1236 - val_loss: 0.1342 - learning_rate: 1.5625e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 14ms/step - auPR: 0.2076 - auROC: 0.8043 - categorical_accuracy: 0.1121 - loss: 0.1364 - val_auPR: 0.2313 - val_auROC: 0.8185 - val_categorical_accuracy: 0.1238 - val_loss: 0.1342 - learning_rate: 1.5625e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 14ms/step - auPR: 0.2079 - auROC: 0.8047 - categorical_accuracy: 0.1126 - loss: 0.1363 - val_auPR: 0.2318 - val_auROC: 0.8189 - val_categorical_accuracy: 0.1253 - val_loss: 0.1341 - learning_rate: 1.5625e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 13ms/step - auPR: 0.2083 - auROC: 0.8049 - categorical_accuracy: 0.1122 - loss: 0.1362 - val_auPR: 0.2313 - val_auROC: 0.8186 - val_categorical_accuracy: 0.1255 - val_loss: 0.1341 - learning_rate: 1.5625e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 14ms/step - auPR: 0.2084 - auROC: 0.8050 - categorical_accuracy: 0.1121 - loss: 0.1361 - val_auPR: 0.2317 - val_auROC: 0.8188 - val_categorical_accuracy: 0.1260 - val_loss: 0.1341 - learning_rate: 1.5625e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 14ms/step - auPR: 0.2088 - auROC: 0.8051 - categorical_accuracy: 0.1123 - loss: 0.1361 - val_auPR: 0.2316 - val_auROC: 0.8190 - val_categorical_accuracy: 0.1263 - val_loss: 0.1340 - learning_rate: 1.5625e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 13ms/step - auPR: 0.2091 - auROC: 0.8051 - categorical_accuracy: 0.1124 - loss: 0.1360 - val_auPR: 0.2318 - val_auROC: 0.8192 - val_categorical_accuracy: 0.1251 - val_loss: 0.1340 - learning_rate: 1.5625e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 14ms/step - auPR: 0.2092 - auROC: 0.8054 - categorical_accuracy: 0.1126 - loss: 0.1360 - val_auPR: 0.2317 - val_auROC: 0.8188 - val_categorical_accuracy: 0.1256 - val_loss: 0.1339 - learning_rate: 1.5625e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 13ms/step - auPR: 0.2092 - auROC: 0.8052 - categorical_accuracy: 0.1123 - loss: 0.1360 - val_auPR: 0.2318 - val_auROC: 0.8187 - val_categorical_accuracy: 0.1252 - val_loss: 0.1339 - learning_rate: 1.5625e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 14ms/step - auPR: 0.2093 - auROC: 0.8055 - categorical_accuracy: 0.1123 - loss: 0.1359 - val_auPR: 0.2321 - val_auROC: 0.8188 - val_categorical_accuracy: 0.1246 - val_loss: 0.1339 - learning_rate: 1.5625e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 13ms/step - auPR: 0.2096 - auROC: 0.8055 - categorical_accuracy: 0.1124 - loss: 0.1359 - val_auPR: 0.2322 - val_auROC: 0.8190 - val_categorical_accuracy: 0.1245 - val_loss: 0.1338 - learning_rate: 1.5625e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 13ms/step - auPR: 0.2097 - auROC: 0.8057 - categorical_accuracy: 0.1127 - loss: 0.1358 - val_auPR: 0.2321 - val_auROC: 0.8187 - val_categorical_accuracy: 0.1256 - val_loss: 0.1339 - learning_rate: 1.5625e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 13ms/step - auPR: 0.2099 - auROC: 0.8056 - categorical_accuracy: 0.1126 - loss: 0.1358 - val_auPR: 0.2319 - val_auROC: 0.8189 - val_categorical_accuracy: 0.1242 - val_loss: 0.1339 - learning_rate: 1.5625e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 13ms/step - auPR: 0.2107 - auROC: 0.8065 - categorical_accuracy: 0.1132 - loss: 0.1356 - val_auPR: 0.2326 - val_auROC: 0.8194 - val_categorical_accuracy: 0.1254 - val_loss: 0.1337 - learning_rate: 3.9063e-06\n",
      "Epoch 64/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 14ms/step - auPR: 0.2112 - auROC: 0.8065 - categorical_accuracy: 0.1132 - loss: 0.1356 - val_auPR: 0.2327 - val_auROC: 0.8191 - val_categorical_accuracy: 0.1258 - val_loss: 0.1337 - learning_rate: 3.9063e-06\n",
      "Epoch 65/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 13ms/step - auPR: 0.2109 - auROC: 0.8067 - categorical_accuracy: 0.1139 - loss: 0.1356 - val_auPR: 0.2327 - val_auROC: 0.8193 - val_categorical_accuracy: 0.1247 - val_loss: 0.1337 - learning_rate: 3.9063e-06\n",
      "Epoch 66/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 14ms/step - auPR: 0.2114 - auROC: 0.8068 - categorical_accuracy: 0.1132 - loss: 0.1355 - val_auPR: 0.2325 - val_auROC: 0.8193 - val_categorical_accuracy: 0.1249 - val_loss: 0.1337 - learning_rate: 3.9063e-06\n",
      "Epoch 67/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 14ms/step - auPR: 0.2111 - auROC: 0.8070 - categorical_accuracy: 0.1135 - loss: 0.1355 - val_auPR: 0.2327 - val_auROC: 0.8193 - val_categorical_accuracy: 0.1266 - val_loss: 0.1337 - learning_rate: 3.9063e-06\n",
      "Epoch 68/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 14ms/step - auPR: 0.2116 - auROC: 0.8069 - categorical_accuracy: 0.1138 - loss: 0.1355 - val_auPR: 0.2328 - val_auROC: 0.8194 - val_categorical_accuracy: 0.1268 - val_loss: 0.1336 - learning_rate: 3.9063e-06\n",
      "Epoch 69/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 13ms/step - auPR: 0.2120 - auROC: 0.8071 - categorical_accuracy: 0.1143 - loss: 0.1354 - val_auPR: 0.2327 - val_auROC: 0.8194 - val_categorical_accuracy: 0.1247 - val_loss: 0.1337 - learning_rate: 1.0000e-06\n",
      "Epoch 70/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 14ms/step - auPR: 0.2118 - auROC: 0.8070 - categorical_accuracy: 0.1140 - loss: 0.1355 - val_auPR: 0.2331 - val_auROC: 0.8196 - val_categorical_accuracy: 0.1267 - val_loss: 0.1336 - learning_rate: 1.0000e-06\n",
      "Epoch 71/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 14ms/step - auPR: 0.2116 - auROC: 0.8071 - categorical_accuracy: 0.1136 - loss: 0.1354 - val_auPR: 0.2328 - val_auROC: 0.8192 - val_categorical_accuracy: 0.1255 - val_loss: 0.1336 - learning_rate: 1.0000e-06\n",
      "Epoch 72/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 14ms/step - auPR: 0.2118 - auROC: 0.8072 - categorical_accuracy: 0.1140 - loss: 0.1354 - val_auPR: 0.2328 - val_auROC: 0.8194 - val_categorical_accuracy: 0.1254 - val_loss: 0.1337 - learning_rate: 1.0000e-06\n",
      "Epoch 73/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 15ms/step - auPR: 0.2118 - auROC: 0.8072 - categorical_accuracy: 0.1141 - loss: 0.1354 - val_auPR: 0.2330 - val_auROC: 0.8196 - val_categorical_accuracy: 0.1268 - val_loss: 0.1336 - learning_rate: 1.0000e-06\n",
      "Epoch 74/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 14ms/step - auPR: 0.2120 - auROC: 0.8072 - categorical_accuracy: 0.1141 - loss: 0.1354 - val_auPR: 0.2328 - val_auROC: 0.8195 - val_categorical_accuracy: 0.1256 - val_loss: 0.1337 - learning_rate: 1.0000e-06\n",
      "Epoch 75/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 14ms/step - auPR: 0.2119 - auROC: 0.8073 - categorical_accuracy: 0.1140 - loss: 0.1354 - val_auPR: 0.2329 - val_auROC: 0.8193 - val_categorical_accuracy: 0.1261 - val_loss: 0.1336 - learning_rate: 1.0000e-06\n",
      "Epoch 76/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 13ms/step - auPR: 0.2119 - auROC: 0.8072 - categorical_accuracy: 0.1141 - loss: 0.1354 - val_auPR: 0.2331 - val_auROC: 0.8196 - val_categorical_accuracy: 0.1262 - val_loss: 0.1335 - learning_rate: 1.0000e-06\n",
      "Epoch 77/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 13ms/step - auPR: 0.2118 - auROC: 0.8072 - categorical_accuracy: 0.1139 - loss: 0.1354 - val_auPR: 0.2330 - val_auROC: 0.8197 - val_categorical_accuracy: 0.1259 - val_loss: 0.1335 - learning_rate: 1.0000e-06\n",
      "Epoch 78/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 13ms/step - auPR: 0.2123 - auROC: 0.8074 - categorical_accuracy: 0.1142 - loss: 0.1354 - val_auPR: 0.2329 - val_auROC: 0.8196 - val_categorical_accuracy: 0.1259 - val_loss: 0.1337 - learning_rate: 1.0000e-06\n",
      "Epoch 79/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 14ms/step - auPR: 0.2120 - auROC: 0.8073 - categorical_accuracy: 0.1138 - loss: 0.1354 - val_auPR: 0.2330 - val_auROC: 0.8196 - val_categorical_accuracy: 0.1265 - val_loss: 0.1336 - learning_rate: 1.0000e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 14ms/step - auPR: 0.2120 - auROC: 0.8073 - categorical_accuracy: 0.1140 - loss: 0.1354 - val_auPR: 0.2330 - val_auROC: 0.8195 - val_categorical_accuracy: 0.1265 - val_loss: 0.1336 - learning_rate: 1.0000e-06\n",
      "Epoch 81/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 14ms/step - auPR: 0.2122 - auROC: 0.8075 - categorical_accuracy: 0.1141 - loss: 0.1354 - val_auPR: 0.2331 - val_auROC: 0.8197 - val_categorical_accuracy: 0.1253 - val_loss: 0.1335 - learning_rate: 1.0000e-06\n",
      "Epoch 82/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 14ms/step - auPR: 0.2118 - auROC: 0.8073 - categorical_accuracy: 0.1141 - loss: 0.1354 - val_auPR: 0.2330 - val_auROC: 0.8195 - val_categorical_accuracy: 0.1258 - val_loss: 0.1336 - learning_rate: 1.0000e-06\n",
      "Epoch 83/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 14ms/step - auPR: 0.2120 - auROC: 0.8072 - categorical_accuracy: 0.1137 - loss: 0.1354 - val_auPR: 0.2330 - val_auROC: 0.8194 - val_categorical_accuracy: 0.1264 - val_loss: 0.1336 - learning_rate: 1.0000e-06\n",
      "Epoch 84/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 14ms/step - auPR: 0.2121 - auROC: 0.8074 - categorical_accuracy: 0.1138 - loss: 0.1354 - val_auPR: 0.2330 - val_auROC: 0.8197 - val_categorical_accuracy: 0.1262 - val_loss: 0.1336 - learning_rate: 1.0000e-06\n",
      "Epoch 85/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 14ms/step - auPR: 0.2121 - auROC: 0.8074 - categorical_accuracy: 0.1143 - loss: 0.1354 - val_auPR: 0.2330 - val_auROC: 0.8196 - val_categorical_accuracy: 0.1269 - val_loss: 0.1336 - learning_rate: 1.0000e-06\n",
      "Epoch 86/100\n",
      "\u001b[1m5532/5532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 14ms/step - auPR: 0.2121 - auROC: 0.8072 - categorical_accuracy: 0.1139 - loss: 0.1354 - val_auPR: 0.2330 - val_auROC: 0.8195 - val_categorical_accuracy: 0.1259 - val_loss: 0.1336 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Evaluation and prediction\n",
    "\n",
    "Evaluation and prediction are the same as peak regression. \n",
    "\n",
    "The next steps you could take are to:\n",
    "1. Evaluate the model on the test set.\n",
    "2. Predict topic probabilities for a given sequence or region.\n",
    "3. Run tfmodisco to find motifs associated with each topic.\n",
    "4. Generate synthetic sequences for each topic using in silico evolution.\n",
    "5. Plot contribution scores per topic for interesting regions or sequences. \n",
    "\n",
    "Refer to [the introduction notebook](project:model_training_and_eval) for more details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crested_py313_tf220",
   "language": "python",
   "name": "crested_py313_tf220_script"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
