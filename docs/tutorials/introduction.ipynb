{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to CREsted\n",
    "\n",
    "In this introductory notebook, we will train a topic classification model and inspect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 15:20:24.115927: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-13 15:20:24.198815: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-13 15:20:25.614317: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-06-13 15:20:32.714606: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "import crested\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the {func}`~crested.import_peaks` function to import data into an {class}`anndata.AnnData` object,\n",
    "with the imported topics as the `AnnData.obs` and the consensus peak regions as the `AnnData.var`.  \n",
    "Below we assume that you have environment variables set to your data paths, but you can simply provide the strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Directory '/staging/leuven/stg_00002/lcb/lmahieu/projects/DeepTopic/biccn_test/otsu' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m adata \u001b[38;5;241m=\u001b[39m \u001b[43mcrested\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_topics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtopics_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/staging/leuven/stg_00002/lcb/lmahieu/projects/DeepTopic/biccn_test/otsu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregions_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/staging/leuven/stg_00002/lcb/lmahieu/projects/DeepTopic/biccn_test/consensus_peaks_bicnn.bed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# topics_subset=[\"topic_1\", \"topic_2\"], # optional subset of topics to import\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m adata\n",
      "File \u001b[0;32m~/Desktop/projects/CREsted/src/crested/_io.py:97\u001b[0m, in \u001b[0;36mimport_topics\u001b[0;34m(topics_folder, regions_file, chromsizes_file, topics_subset, remove_empty_regions, compress)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Input checks\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m topics_folder\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopics_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m regions_file\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregions_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Directory '/staging/leuven/stg_00002/lcb/lmahieu/projects/DeepTopic/biccn_test/otsu' not found"
     ]
    }
   ],
   "source": [
    "adata = crested.import_topics(\n",
    "    topics_folder=\"/staging/leuven/stg_00002/lcb/lmahieu/projects/DeepTopic/biccn_test/otsu\",\n",
    "    regions_file=\"/staging/leuven/stg_00002/lcb/lmahieu/projects/DeepTopic/biccn_test/consensus_peaks_bicnn.bed\",\n",
    "    compress=True,\n",
    "    # topics_subset=[\"topic_1\", \"topic_2\"], # optional subset of topics to import\n",
    ")\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model, we'll need to add a *split* column to our dataset, which we can do using `crested.pp.train_val_test_split()`.  \n",
    "We can add a `random_state` to ensure the data will be split in the same manner in the future when `shuffle=True`(default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split\n",
      "train    437593\n",
      "test      54700\n",
      "val       54700\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_topics</th>\n",
       "      <th>chr</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chr1:3094805-3095305</th>\n",
       "      <td>5</td>\n",
       "      <td>chr1</td>\n",
       "      <td>3094805</td>\n",
       "      <td>3095305</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:3095470-3095970</th>\n",
       "      <td>0</td>\n",
       "      <td>chr1</td>\n",
       "      <td>3095470</td>\n",
       "      <td>3095970</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:3112174-3112674</th>\n",
       "      <td>1</td>\n",
       "      <td>chr1</td>\n",
       "      <td>3112174</td>\n",
       "      <td>3112674</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:3113534-3114034</th>\n",
       "      <td>2</td>\n",
       "      <td>chr1</td>\n",
       "      <td>3113534</td>\n",
       "      <td>3114034</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:3119746-3120246</th>\n",
       "      <td>8</td>\n",
       "      <td>chr1</td>\n",
       "      <td>3119746</td>\n",
       "      <td>3120246</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:169879313-169879813</th>\n",
       "      <td>3</td>\n",
       "      <td>chrX</td>\n",
       "      <td>169879313</td>\n",
       "      <td>169879813</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:169880181-169880681</th>\n",
       "      <td>0</td>\n",
       "      <td>chrX</td>\n",
       "      <td>169880181</td>\n",
       "      <td>169880681</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:169925477-169925977</th>\n",
       "      <td>1</td>\n",
       "      <td>chrX</td>\n",
       "      <td>169925477</td>\n",
       "      <td>169925977</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:169948550-169949050</th>\n",
       "      <td>0</td>\n",
       "      <td>chrX</td>\n",
       "      <td>169948550</td>\n",
       "      <td>169949050</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:169950978-169951478</th>\n",
       "      <td>0</td>\n",
       "      <td>chrX</td>\n",
       "      <td>169950978</td>\n",
       "      <td>169951478</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546993 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          n_topics   chr      start        end  split\n",
       "region                                                               \n",
       "chr1:3094805-3095305             5  chr1    3094805    3095305  train\n",
       "chr1:3095470-3095970             0  chr1    3095470    3095970  train\n",
       "chr1:3112174-3112674             1  chr1    3112174    3112674   test\n",
       "chr1:3113534-3114034             2  chr1    3113534    3114034  train\n",
       "chr1:3119746-3120246             8  chr1    3119746    3120246  train\n",
       "...                            ...   ...        ...        ...    ...\n",
       "chrX:169879313-169879813         3  chrX  169879313  169879813  train\n",
       "chrX:169880181-169880681         0  chrX  169880181  169880681  train\n",
       "chrX:169925477-169925977         1  chrX  169925477  169925977  train\n",
       "chrX:169948550-169949050         0  chrX  169948550  169949050  train\n",
       "chrX:169950978-169951478         0  chrX  169950978  169951478    val\n",
       "\n",
       "[546993 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can split randomly on the regions\n",
    "crested.pp.train_val_test_split(\n",
    "    adata, type=\"random\", val_size=0.1, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Or, choose the chromosomes for the validation and test sets\n",
    "# enhai.pp.train_val_test_split(\n",
    "#     adata, type=\"chr\", chr_val=[\"chr4\", \"chrX\"], chr_test=[\"chr2\", \"chr3\"]\n",
    "# )\n",
    "\n",
    "print(adata.var[\"split\"].value_counts())\n",
    "adata.var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enhancerai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
