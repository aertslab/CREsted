{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepTopic\n",
    "\n",
    "Sample notebook to train DeepTopic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enhancerai as enhai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use function {func}`enhancerai.import_topics` to import data into an {class}`anndata.AnnData` object,\n",
    "with the imported topics as the `AnnData.obs` and the consensus peak regions as the `AnnData.var`.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre1/project/stg_00002/lcb/lmahieu/projects/EnhancerAI/src/enhancerai/_io.py:127: UserWarning: 107610 consensus regions are not open in any topic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 80 × 546993\n",
       "    obs: 'file_path', 'n_open_regions'\n",
       "    var: 'n_topics', 'chr', 'start', 'end'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = enhai.import_topics(\n",
    "    topics_folder=\"/staging/leuven/stg_00002/lcb/lmahieu/projects/DeepTopic/biccn_test/otsu\",\n",
    "    peaks_file=\"/staging/leuven/stg_00002/lcb/lmahieu/projects/DeepTopic/biccn_test/consensus_peaks_bicnn.bed\",\n",
    "    compress=True,\n",
    "    # topics_subset=[\"topic_1\", \"topic_2\"], # optional subset of topics to import\n",
    ")\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `import_topics` function will also add a couple of columns with variables of interest to your `AnnData.obs` and `Anndata.var` (AnnData.obs.n_open_regions and AnnData.var.n_topics), which you can use to inspect and get a feel of your data.\n",
    "\n",
    "To be able to do region to topic modelling, we'll need to add the DNA sequences to our `AnnData` object. We can do this by using {func}`enhancerai.pp.add_dna_sequence` and referencing to a local Fasta file with the `fasta_path=/path/to/local.fasta` argument. Alternatively, we can simple provide a name of a genome, which will use genomepy to download a reference genome. The DNA sequences will be located in your AnnData.varm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model, we'll need to add a *split* column to our dataset, which we can do using {func}`enhancerai.pp.train_val_test`.  \n",
    "We can add a `random_state` to ensure the data will be split in the same manner in the future when `shuffle=True`(default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split\n",
      "train    437593\n",
      "test      54700\n",
      "val       54700\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_topics</th>\n",
       "      <th>chr</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chr1:3094805-3095305</th>\n",
       "      <td>5</td>\n",
       "      <td>chr1</td>\n",
       "      <td>3094805</td>\n",
       "      <td>3095305</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:3095470-3095970</th>\n",
       "      <td>0</td>\n",
       "      <td>chr1</td>\n",
       "      <td>3095470</td>\n",
       "      <td>3095970</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:3112174-3112674</th>\n",
       "      <td>1</td>\n",
       "      <td>chr1</td>\n",
       "      <td>3112174</td>\n",
       "      <td>3112674</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:3113534-3114034</th>\n",
       "      <td>2</td>\n",
       "      <td>chr1</td>\n",
       "      <td>3113534</td>\n",
       "      <td>3114034</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:3119746-3120246</th>\n",
       "      <td>8</td>\n",
       "      <td>chr1</td>\n",
       "      <td>3119746</td>\n",
       "      <td>3120246</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:169879313-169879813</th>\n",
       "      <td>3</td>\n",
       "      <td>chrX</td>\n",
       "      <td>169879313</td>\n",
       "      <td>169879813</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:169880181-169880681</th>\n",
       "      <td>0</td>\n",
       "      <td>chrX</td>\n",
       "      <td>169880181</td>\n",
       "      <td>169880681</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:169925477-169925977</th>\n",
       "      <td>1</td>\n",
       "      <td>chrX</td>\n",
       "      <td>169925477</td>\n",
       "      <td>169925977</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:169948550-169949050</th>\n",
       "      <td>0</td>\n",
       "      <td>chrX</td>\n",
       "      <td>169948550</td>\n",
       "      <td>169949050</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:169950978-169951478</th>\n",
       "      <td>0</td>\n",
       "      <td>chrX</td>\n",
       "      <td>169950978</td>\n",
       "      <td>169951478</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546993 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          n_topics   chr      start        end  split\n",
       "region                                                               \n",
       "chr1:3094805-3095305             5  chr1    3094805    3095305  train\n",
       "chr1:3095470-3095970             0  chr1    3095470    3095970  train\n",
       "chr1:3112174-3112674             1  chr1    3112174    3112674   test\n",
       "chr1:3113534-3114034             2  chr1    3113534    3114034  train\n",
       "chr1:3119746-3120246             8  chr1    3119746    3120246  train\n",
       "...                            ...   ...        ...        ...    ...\n",
       "chrX:169879313-169879813         3  chrX  169879313  169879813  train\n",
       "chrX:169880181-169880681         0  chrX  169880181  169880681  train\n",
       "chrX:169925477-169925977         1  chrX  169925477  169925977  train\n",
       "chrX:169948550-169949050         0  chrX  169948550  169949050  train\n",
       "chrX:169950978-169951478         0  chrX  169950978  169951478    val\n",
       "\n",
       "[546993 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can split randomly on the regions\n",
    "enhai.pp.train_val_test_split(\n",
    "    adata, type=\"random\", val_size=0.1, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Or, choose the chromosomes for the validation and test sets\n",
    "# enhai.pp.train_val_test_split(\n",
    "#     adata, type=\"chr\", chr_val=[\"chr4\", \"chrX\"], chr_test=[\"chr2\", \"chr3\"]\n",
    "# )\n",
    "\n",
    "print(adata.var[\"split\"].value_counts())\n",
    "adata.var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre1/project/stg_00002/mambaforge/vsc35862/envs/enhancerai/lib/python3.11/site-packages/torch/nn/modules/conv.py:306: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1040.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "from enhancerai.tl.zoo import DeepTopicCNN\n",
    "from enhancerai.tl.dataloaders import AnnDataModule\n",
    "from enhancerai.tl.tasks import TopicClassification\n",
    "\n",
    "# Chosen model architecture\n",
    "architecture = DeepTopicCNN(num_classes=80, seq_len=500)\n",
    "\n",
    "# Datamodule, containing the train, validation and test dataloaders\n",
    "datamodule = AnnDataModule(\n",
    "    adata,\n",
    "    genome_file ='/staging/leuven/res_00001/genomes/10xgenomics/CellRangerARC/refdata-cellranger-arc-mm10-2020-A-2.0.0/fasta/genome.fa',\n",
    "    batch_size=256,\n",
    "    num_workers=30,\n",
    "    in_memory=True,\n",
    "    random_reverse_complement=True\n",
    ")\n",
    "\n",
    "# Task definition (losses, metrics, and how a training step is performed), initialized\n",
    "# with the chosen model architecture\n",
    "task = TopicClassification(80, architecture, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlukas-mahieu\u001b[0m (\u001b[33mlukas-mahieu-vib\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240412_173133-uxbq84qs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lukas-mahieu-vib/test-biccn-enhancerai/runs/uxbq84qs' target=\"_blank\">dainty-gorge-21</a></strong> to <a href='https://wandb.ai/lukas-mahieu-vib/test-biccn-enhancerai' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lukas-mahieu-vib/test-biccn-enhancerai' target=\"_blank\">https://wandb.ai/lukas-mahieu-vib/test-biccn-enhancerai</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lukas-mahieu-vib/test-biccn-enhancerai/runs/uxbq84qs' target=\"_blank\">https://wandb.ai/lukas-mahieu-vib/test-biccn-enhancerai/runs/uxbq84qs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "/lustre1/project/stg_00002/mambaforge/vsc35862/envs/enhancerai/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /lustre1/project/stg_00002/mambaforge/vsc35862/envs/ ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/lustre1/project/stg_00002/mambaforge/vsc35862/envs/enhancerai/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /lustre1/project/stg_00002/mambaforge/vsc35862/envs/ ...\n",
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sequences into memory...\n",
      "Loading sequences into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre1/project/stg_00002/mambaforge/vsc35862/envs/enhancerai/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:653: Checkpoint directory /lustre1/project/stg_00002/lcb/lmahieu/projects/EnhancerAI/docs/notebooks/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | loss          | BCELoss          | 0     \n",
      "1 | model         | DeepTopicCNN     | 11.7 M\n",
      "2 | train_metrics | MetricCollection | 0     \n",
      "3 | val_metrics   | MetricCollection | 0     \n",
      "4 | test_metrics  | MetricCollection | 0     \n",
      "---------------------------------------------------\n",
      "11.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.7 M    Total params\n",
      "46.777    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre1/project/stg_00002/mambaforge/vsc35862/envs/enhancerai/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 30 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:   4%|▎         | 60/1710 [00:07<03:18,  8.31it/s, v_num=84qs, train/loss_step=0.133, val/loss=0.134, train/loss_epoch=0.137] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre1/project/stg_00002/mambaforge/vsc35862/envs/enhancerai/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "from enhancerai.tl import fit\n",
    "\n",
    "# Define the Trainer object with run information\n",
    "fit(task, datamodule, project_name=\"test-biccn-enhancerai\", max_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/luna.kuleuven.be/u0166574/miniconda3/envs/enhancerai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 97/97 [00:03<00:00, 24.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/BinaryAUROC      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9289787411689758     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/BinaryAccuracy    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9025986790657043     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/BinaryF1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8275322914123535     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test/BinaryPrecision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9608974456787109     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/BinaryRecall     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7406820058822632     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.32621148228645325    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test/BinaryAUROC     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9289787411689758    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test/BinaryAccuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9025986790657043    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test/BinaryF1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8275322914123535    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test/BinaryPrecision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9608974456787109    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test/BinaryRecall    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7406820058822632    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.32621148228645325   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 725/725 [00:26<00:00, 27.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.03991739, 0.01989121, 0.9506258 ],\n",
       "       [0.04678131, 0.01655637, 0.9515035 ],\n",
       "       [0.26182953, 0.23671702, 0.5713035 ],\n",
       "       ...,\n",
       "       [0.22486855, 0.18705001, 0.60592073],\n",
       "       [0.2437813 , 0.32724276, 0.41594404],\n",
       "       [0.3834117 , 0.28862736, 0.38204765]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from enhancerai.tl import evaluate, predict\n",
    "import numpy as np\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "evaluate(task, datamodule)\n",
    "\n",
    "# Predict the labels of the full dataset\n",
    "results = predict(task, datamodule)\n",
    "results = np.vstack([x.cpu().numpy() for x in results])\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enhancerai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
