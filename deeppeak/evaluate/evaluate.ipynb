{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individiual evaluation/interpretation notebook\n",
    "\n",
    "Inspect individual predictions and metrics per/across cell types.\n",
    "Use the python modules (evaluation.py & interpret.py) to perform evaluations accross the entire test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!module load cuDNN/8.7.0.84-CUDA-11.8.0  # change to your CUDA version\n",
    "!module load cluster/wice/dedicated_big_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 12:05:48.830866: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-22 12:05:48.879183: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-22 12:05:48.879210: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-22 12:05:48.879243: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-22 12:05:48.889792: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pyfaidx\n",
    "import os\n",
    "from utils.one_hot_encoding import get_hot_encoding_table, regions_to_hot_encoding\n",
    "from utils.plot import plot_predictions_vs_groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "MODEL_DIR = '../../checkpoints/mouse/2023-12-21_10:19/'  # change this\n",
    "GENOME_FASTA_PATH = '../../data/raw/genome.fa'  # change this\n",
    "SPLIT = 'test'  # change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find idx of interest to inspect\n",
    "CHR = 'chr18'  # change this\n",
    "REGION_START = 61106000  # change this\n",
    "REGION_END = 61110000  # change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_bed_file = os.path.join(MODEL_DIR, \"regions.bed\")\n",
    "one_hot_encoding_table = get_hot_encoding_table()\n",
    "genomic_pyfasta = pyfaidx.Fasta(GENOME_FASTA_PATH, sequence_always_upper=True)\n",
    "targets = np.load(os.path.join(MODEL_DIR, \"targets.npz\"))[SPLIT]\n",
    "region_split_ids = np.load(os.path.join(MODEL_DIR, \"region_split_ids.npz\"))[SPLIT]\n",
    "\n",
    "classnames = []\n",
    "with open(\n",
    "    os.path.join(MODEL_DIR, \"cell_type_mapping.tsv\"), \"r\"\n",
    ") as cell_mapping:\n",
    "    for line in cell_mapping:\n",
    "        classnames.append(line.strip().split(\"\\t\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One hot encoding sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1070.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# One hot encode regions of interest\n",
    "regions_of_interest = {}\n",
    "\n",
    "with open(regions_bed_file, \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        line = line.strip()\n",
    "        if line:  # Check if the line is not empty\n",
    "            chrom, start, end = line.split()[:3]\n",
    "            start, end = int(start), int(end)\n",
    "\n",
    "            if chrom == CHR and REGION_START <= start <= REGION_END and REGION_START <= end <= REGION_END:\n",
    "                regions_of_interest[i] = line.split('\\t')\n",
    "\n",
    "idx_of_interest = regions_of_interest.keys()\n",
    "\n",
    "seqs_one_hot = regions_to_hot_encoding(\n",
    "    regions_bed_filename=regions_bed_file,\n",
    "    genomic_pyfasta=genomic_pyfasta,\n",
    "    hot_encoding_table=one_hot_encoding_table,\n",
    "    idx=idx_of_interest,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{250544: ['chr18', '61106697', '61108811', 'chr18:61106697-61108811'],\n",
       " 250545: ['chr18', '61107570', '61109684', 'chr18:61107570-61109684']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One hot shape: (2, 2114, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"One hot shape:\", seqs_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect individual predictions vs ground truth accross multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../checkpoints/mouse/2023-12-21_10:19/checkpoints/30.keras',\n",
       " '../../checkpoints/mouse/2023-12-21_10:19/checkpoints/28.keras',\n",
       " '../../checkpoints/mouse/2023-12-21_10:19/checkpoints/29.keras',\n",
       " '../../checkpoints/mouse/2023-12-21_10:19/checkpoints/27.keras']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare evolution of model training\n",
    "# you can also manually change to a list of absolute model paths you want to compare\n",
    "model_paths = [os.path.join(MODEL_DIR, 'checkpoints', name) for name in os.listdir(os.path.join(MODEL_DIR, 'checkpoints'))]  \n",
    "model_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA A100-SXM4-80GB, compute capability 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 11:50:19.322695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78913 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:18:00.0, compute capability: 8.0\n",
      "2023-12-22 11:50:20.771953: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for model in model_paths:\n",
    "    model = tf.keras.models.load_model(model, compile=False)\n",
    "    prediction = model.predict(seqs_one_hot)\n",
    "    print(prediction)\n",
    "    break\n",
    "plot_predictions_vs_groundtruth(...)\n",
    "\n",
    "# TODO:finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeppeak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
